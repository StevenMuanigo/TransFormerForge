server:
  host: "0.0.0.0"
  port: 8080
  workers: 4
  request_timeout_ms: 30000

models:
  default: "bert-base-uncased"
  cache_dir: "./models_cache"
  auto_download: true
  available_models:
    - name: "bert-base-uncased"
      task: "sentiment-analysis"
      repo: "distilbert-base-uncased-finetuned-sst-2-english"
    - name: "roberta-large"
      task: "text-classification"
      repo: "roberta-large-mnli"
    - name: "gpt2"
      task: "text-generation"
      repo: "gpt2"

inference:
  batch_size: 32
  max_length: 512
  device: "auto"  # auto, cpu, cuda:0
  num_threads: 8
  enable_gpu: true

preprocessing:
  lowercase: true
  remove_special_chars: false
  max_input_length: 512

monitoring:
  enable_metrics: true
  metrics_port: 9090
  log_level: "info"  # trace, debug, info, warn, error
  log_format: "json"  # json, pretty
  log_file: "./logs/transformer-forge.log"

cache:
  enable: true
  ttl_seconds: 3600
  max_entries: 10000

performance:
  async_workers: 16
  queue_size: 1000
  enable_benchmarking: true
